# ğŸ“ Titanic Survival Prediction Project

---

## ğŸ¯ Objective:
To understand and prepare the Titanic dataset for building a predictive machine learning model. This includes data cleaning, exploratory data analysis (EDA), handling missing values and outliers, and drawing inferences from visualizations.

---

## âœ… Task 1: Data Cleaning & Preprocessing

### ğŸ” Goals:
- Handle missing values appropriately.
- Treat outliers to prevent distortion in modeling.
- Perform initial data checks.

### ğŸ“Œ Key Steps:
1. **Loaded the Titanic dataset.**
2. **Handled Missing Values:**
   - `Cabin` filled with `'Unknown'`.
   - `Age` and `Fare` filled with median values.
3. **Outlier Detection & Removal:**
   - Detected using boxplots for `Age` and `Fare`.
   - Removed entries where `Fare > 300` and `Age > 80`.

### ğŸ§¹ Outcome:
- Dataset cleaned and ready for exploratory analysis.
- Missing values and outliers no longer distort the feature distributions.

---

## âœ… Task 2: Exploratory Data Analysis (EDA)

### ğŸ” Goals:
- Analyze data distributions and relationships between features.
- Use visualizations to infer patterns and trends.

### ğŸ“Š Key Steps:
1. **Generated Summary Statistics:**
   - Mean, median, standard deviation helped understand spread.

2. **Plotted Visuals:**
   - **Histograms** for `Age` and `Fare`.
   - **Boxplots** to detect outliers.
   - **Bar plots** comparing `Survived` with `Sex` and `Pclass`.
   - **Correlation Heatmap** to find relationships between numeric features.
   - **Pairplot** visualizing feature relationships by `Survived`.

3. **Handled Categorical Encoding:**
   - Used one-hot encoding for categorical features (`Sex`, `Embarked`, etc.).

---

## ğŸ§  Inference Summary (From Visuals):

- **Survival Rate by Sex:** Females had a significantly higher survival rate than males.
- **Survival Rate by Class:** 1st class passengers had better survival odds.
- **Fare:** Right-skewed; higher fares generally linked to survival.
- **Age:** Most passengers were 20â€“40 years old; survival scattered across ages.
- **Correlation:** Strong negative correlation between `Pclass` and `Fare`; moderate positive correlation between `SibSp` and `Parch`.

---
# ğŸ task 3 House Price Prediction (Linear Regression)

A simple ML project that predicts house prices using Linear Regression on `Housing.csv`.

## ğŸ”§ Steps
1. Load & preprocess data (encoding categoricals)
2. Train-test split
3. Train Linear Regression model
4. Evaluate using MAE, MSE, RÂ²
5. Plot actual vs predicted, view coefficients

## ğŸ“Š Sample Results
- MAE: ~â‚¹9.7 L
- RÂ² Score: ~0.65

## ğŸ“¦ Libraries
pandas, numpy, sklearn, matplotlib, seaborn

# task 4 Logistic Regression - Breast Cancer Classification

This project demonstrates how to apply **Logistic Regression** for binary classification on the **Breast Cancer Wisconsin dataset**.

## Project Steps
1. **Dataset Selection**
   - Uses `data.csv` (Breast Cancer Wisconsin dataset).
2. **Data Preprocessing**
   - Dropped unnecessary columns: `id`, `Unnamed: 32`
   - Encoded target variable: `M` â†’ 1 (Malignant), `B` â†’ 0 (Benign)
3. **Train/Test Split & Standardization**
   - Used 80% training, 20% testing
   - Standardized features using `StandardScaler`
4. **Model Training**
   - Trained a Logistic Regression model using scikit-learn
5. **Model Evaluation**
   - Confusion Matrix
   - Precision
   - Recall
   - ROC-AUC score
   - ROC Curve plot
6. **Threshold Tuning**
   - Example with threshold = 0.3 to show effect on precision and recall
7. **Sigmoid Function Explanation**
   - Plotted sigmoid curve
   - Explained its role in converting model outputs to probabilities

     # Heart Disease Prediction - Decision Tree & Random Forest

## ğŸ“ŒTask 5 Project Overview
This project uses the **Heart Disease Dataset** to train and evaluate two machine learning models:
- **Decision Tree Classifier**
- **Random Forest Classifier**

We:
1. Train and visualize a Decision Tree.
2. Analyze overfitting by controlling tree depth.
3. Train a Random Forest and compare accuracy.
4. Interpret feature importances.
5. Evaluate both models using cross-validation.

---

## ğŸ“‚ Dataset
The dataset used is `heart.csv`, which contains various medical attributes such as:
- Age, sex, chest pain type, blood pressure, cholesterol, etc.
- Target: `1` â†’ Heart disease, `0` â†’ No heart disease.

---

# TASK 6 KNN Classification on Iris Dataset

## Steps Performed
1. **Dataset**  
   - Used `Iris.csv` dataset.  
   - Dropped ID column.  
   - Encoded species labels into numbers.  
   - Normalized features using `StandardScaler`.  

2. **Model**  
   - Applied `KNeighborsClassifier` from `sklearn`.  
   - Tested different `K` values to find the best accuracy.  

3. **Evaluation**  
   - Computed accuracy score.  
   - Created confusion matrix.  

4. **Visualization**  
   - Plotted decision boundaries using first two normalized features.  
   - Colors: Red (Setosa), Green (Versicolor), Blue (Virginica).  

## Output
- Best K value  
- Accuracy score  
- Confusion matrix plot  
- Decision boundary plot

# ğŸ— Breast Cancer Classification

## ğŸ“Œ Task
Train a **Support Vector Machine (SVM)** ğŸ–¥ on the **Breast Cancer Wisconsin dataset** ğŸ©º and visualize **decision boundaries** ğŸŒˆ for two selected features.

## ğŸ“‚ Dataset
- Source: `sklearn.datasets.load_breast_cancer()`
- Target: Malignant (0) / Benign (1)

## ğŸ›  Steps
1ï¸âƒ£ Import libraries  
2ï¸âƒ£ Load & inspect dataset  
3ï¸âƒ£ Select 2 features for plotting  
4ï¸âƒ£ Split into train/test sets  
5ï¸âƒ£ Train SVM classifier  
6ï¸âƒ£ Plot decision boundaries & accuracy score  

## ğŸš€ Output
- Graph with decision boundary separation ğŸ–Œ  
- Accuracy printed in console ğŸ“ˆ

 # TASK 8 ğŸ§  K-Means Clustering on Mall Customers Dataset

## ğŸ“Œ Steps Performed
1ï¸âƒ£ **Load & Explore Dataset**  
- Loaded `Mall_Customers.csv` using Pandas  
- Selected only numerical features for clustering  
- Standardized features with `StandardScaler`  

2ï¸âƒ£ **PCA (Optional) for 2D Visualization**  
- Reduced dimensions to 2 using `PCA` for plotting purposes  

3ï¸âƒ£ **Find Optimal K (Elbow Method)**  
- Plotted `Inertia vs K` curve  
- Chose optimal K based on elbow point  

4ï¸âƒ£ **Fit K-Means Model**  
- Applied `KMeans` with optimal K  
- Predicted cluster labels for each customer  

5ï¸âƒ£ **Visualize Clusters**  
- Plotted customers in PCA space with color-coded clusters  
- Marked cluster centroids in red  

6ï¸âƒ£ **Evaluate Clustering**  
- Calculated **Silhouette Score** to measure clustering quality  

---
# ğŸ¬ **Movie Recommendation System Project**

A **Movie Recommender System** built with **Python**, **Scikit-learn**, **Pandas**, and **Streamlit**.  
It suggests movies based on user preferences using **Content-Based Filtering**, **Collaborative Filtering**, and a **Hybrid Approach**.  
Optionally, it can also fetch **movie posters from TMDb API**.

---

## âœ¨ **Features**
- **Content-based filtering** (TF-IDF + cosine similarity on genres)  
- **Collaborative filtering** (latent factor model with Truncated SVD)  
- **Hybrid recommendations** (mix of content + collaborative)  
- **Genre-based search option**  
- **Interactive Streamlit UI**  
- **Optional TMDb API integration** for fetching posters  

---

## ğŸ“‚ **Project Structure**
- `app.py` â†’ Main Streamlit web app  
- `requirements.txt` â†’ Dependencies  
- `README.md` â†’ Project info  
- `data/` â†’ Place `movies.csv` & `ratings.csv` here  

---












